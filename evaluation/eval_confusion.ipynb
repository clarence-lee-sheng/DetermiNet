{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "hoooo\n",
      "<pycocotools.coco.COCO object at 0x0000026C0DD5B0A0>\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=7.74s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.02s).\n",
      "TP:  [1999. 1999. 1999. 1999. 1999. 1999. 1999. 1999. 1999. 1999.]\n",
      "FP [22017. 22017. 22017. 22017. 22017. 22017. 22017. 22017. 22017. 22017.]\n",
      "FN:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "AP:  0.08323617588274482\n",
      "TPs:  1999.0 FPs:  22017.0 FNs:  1.0\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "hoooo\n",
      "<pycocotools.coco.COCO object at 0x0000026C0DCEDD90>\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=7.61s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.01s).\n",
      "TP:  [2000. 2000. 2000. 2000. 2000. 2000. 2000. 2000. 2000. 2000.]\n",
      "FP [17879. 17879. 17879. 17879. 17879. 17879. 17879. 17879. 17879. 17879.]\n",
      "FN:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "AP:  0.10060868252930225\n",
      "TPs:  2000.0 FPs:  17879.0 FNs:  0.0\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "hoooo\n",
      "<pycocotools.coco.COCO object at 0x0000026C0DCE2F10>\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=7.35s).\n",
      "Accumulating evaluation results...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m cocoEval\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mimgIds \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(cocoGt\u001b[39m.\u001b[39mgetImgIds())\n\u001b[0;32m     54\u001b[0m cocoEval\u001b[39m.\u001b[39mevaluate()\n\u001b[1;32m---> 55\u001b[0m cocoEval\u001b[39m.\u001b[39;49maccumulate()\n\u001b[0;32m     56\u001b[0m \u001b[39m# cocoEval.summarize()\u001b[39;00m\n\u001b[0;32m     57\u001b[0m tp, fp, fn \u001b[39m=\u001b[39m cocoEval\u001b[39m.\u001b[39mget_confusion()\n",
      "File \u001b[1;32mc:\\Users\\clshe\\Documents\\python-envs\\ai_env\\lib\\site-packages\\pycocotools\\cocoeval.py:415\u001b[0m, in \u001b[0;36maccumulate\u001b[1;34m(self, p)\u001b[0m\n\u001b[0;32m    413\u001b[0m inds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msearchsorted(rc, p\u001b[39m.\u001b[39mrecThrs, side\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 415\u001b[0m     \u001b[39mfor\u001b[39;00m ri, pi \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(inds):\n\u001b[0;32m    416\u001b[0m         q[ri] \u001b[39m=\u001b[39m pr[pi]\n\u001b[0;32m    417\u001b[0m         ss[ri] \u001b[39m=\u001b[39m dtScoresSorted[pi]\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\clshe\\Documents\\python-envs\\ai_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1387\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(a, v, side, sorter)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[0;32m   1320\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearchsorted\u001b[39m(a, v, side\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m, sorter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1321\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m \u001b[39m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1385\u001b[0m \n\u001b[0;32m   1386\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39msearchsorted\u001b[39;49m\u001b[39m'\u001b[39;49m, v, side\u001b[39m=\u001b[39;49mside, sorter\u001b[39m=\u001b[39;49msorter)\n",
      "File \u001b[1;32mc:\\Users\\clshe\\Documents\\python-envs\\ai_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json \n",
    "import os \n",
    "from collections import defaultdict\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "pred_filename = r'../annotations/confusion_matrix/oracle/oracle.json'\n",
    "gt_filename = r'../annotations/confusion_matrix/oracle/modgt_oracle.json'\n",
    "\n",
    "temp_pred_filename = r'../annotations/confusion_matrix/temp/temp_preds.json'\n",
    "temp_gt_filename = r'../annotations/confusion_matrix/temp/temp_gt.json'\n",
    "\n",
    "preds = json.load(open(pred_filename, 'r'))\n",
    "gts = json.load(open(gt_filename, 'r'))\n",
    "\n",
    "determiners = [\"a\", \"an\", \"the\", \"any\", \"all\", \"no\", \"every\", \"each\", \"my\", \"your\", \"our\", \"this\", \"these\", \"that\", \"those\", \"few\", \"several\", \"many\", \"some\", \"little\", \"much\", \"both\", \"neither\", \"either\", \"half\"]\n",
    "\n",
    "temp_preds = \"temp_preds.json\"\n",
    "temp_gt = \"temp_gt.json\"\n",
    "\n",
    "images = gts[\"images\"]\n",
    "\n",
    "img_det_map = defaultdict(list)\n",
    "gt_det_map = defaultdict(list)\n",
    "preds_det_map = defaultdict(list)\n",
    "\n",
    "for img in images:\n",
    "    img_id = img[\"id\"]\n",
    "    det = img[\"caption\"].split()[0]\n",
    "    img_det_map[img_id] = det\n",
    "\n",
    "for ann in gts[\"annotations\"]:\n",
    "    gt_det_map[img_det_map[ann[\"image_id\"]]].append(ann)\n",
    "\n",
    "for ann in preds:\n",
    "    preds_det_map[img_det_map[ann[\"image_id\"]]].append(ann)\n",
    "\n",
    "confusion = defaultdict(lambda: defaultdict(int))\n",
    "for det in determiners:\n",
    "    temp_gts = {\"images\": images, \"annotations\": gt_det_map[det], \"categories\": gts[\"categories\"]}\n",
    "    temp_preds = preds_det_map[det]\n",
    "\n",
    "    json.dump(temp_gts, open(temp_gt_filename, 'w'))\n",
    "    json.dump(temp_preds, open(temp_pred_filename, 'w'))\n",
    "\n",
    "    cocoGt = COCO(temp_gt_filename)\n",
    "    cocoDt = cocoGt.loadRes(temp_pred_filename)\n",
    "\n",
    "    annType = \"bbox\"\n",
    "\n",
    "    cocoEval = COCOeval(cocoGt, cocoDt, annType)\n",
    "   \n",
    "    cocoEval.params.imgIds = sorted(cocoGt.getImgIds())\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "    tp, fp, fn = cocoEval.get_confusion()\n",
    "\n",
    "    confusion[det][\"tp\"] = tp\n",
    "    confusion[det][\"fp\"] = fp\n",
    "    confusion[det][\"fn\"] = fn\n",
    "\n",
    "for det in determiners: \n",
    "    print(det, \"TP: \", confusion[det][\"tp\"], \"FP: \", confusion[det][\"fp\"], \"FN: \", confusion[det][\"fn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "determiners = [\"a\", \"an\", \"the\", \"any\", \"all\", \"no\", \"every\", \"each\", \"my\", \"your\", \"our\", \"this\", \"these\", \"that\", \"those\", \"few\", \"several\", \"many\", \"some\", \"little\", \"much\", \"both\", \"neither\", \"either\", \"half\"]\n",
    "print(len(determiners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a TP:  643.0 FP:  569.0 FN:  1357.0\n",
      "an TP:  724.0 FP:  574.0 FN:  1276.0\n",
      "all TP:  6922.0 FP:  235.0 FN:  113.0\n",
      "any TP:  518.0 FP:  213.0 FN:  3948.0\n",
      "every TP:  7989.0 FP:  153.0 FN:  35.0\n",
      "my TP:  2819.0 FP:  869.0 FN:  1197.0\n",
      "your TP:  2576.1 FP:  1589.9 FN:  1426.9\n",
      "this TP:  442.0 FP:  470.0 FN:  1558.0\n",
      "that TP:  431.2 FP:  454.8 FN:  1568.8\n",
      "these TP:  5425.0 FP:  729.0 FN:  580.0\n",
      "those TP:  5425.0 FP:  888.0 FN:  599.0\n",
      "some TP:  7061.0 FP:  1218.0 FN:  619.0\n",
      "many TP:  16953.0 FP:  86.0 FN:  46.0\n",
      "few TP:  4823.0 FP:  39.0 FN:  152.0\n",
      "both TP:  3952.0 FP:  84.0 FN:  48.0\n",
      "neither TP:  3955.0 FP:  65.0 FN:  45.0\n",
      "little TP:  4487.0 FP:  974.0 FN:  595.0\n",
      "much TP:  3782.0 FP:  475.0 FN:  1207.0\n",
      "either TP:  623.0 FP:  654.0 FN:  1377.0\n",
      "our TP:  6299.1 FP:  3190.9 FN:  1731.9\n",
      "no TP:  5846.0 FP:  211.0 FN:  112.0\n",
      "several TP:  13215.0 FP:  1531.0 FN:  281.0\n",
      "half TP:  1677.8 FP:  1767.2 FN:  2316.2\n",
      "each TP:  7000.0 FP:  117.0 FN:  27.0\n",
      "the TP:  1892.0 FP:  129.0 FN:  108.0\n"
     ]
    }
   ],
   "source": [
    "for det in determiners: \n",
    "    print(det, \"TP: \", confusion[det][\"tp\"], \"FP: \", confusion[det][\"fp\"], \"FN: \", confusion[det][\"fn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
