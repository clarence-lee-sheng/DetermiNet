{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b3dec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = [\"annotations_train.json\", \"annotations_val.json\", \"annotations_test.json\"]\n",
    "\n",
    "#######################################################################################\n",
    "############################# CHANGE FILENAMES HERE ###################################\n",
    "#######################################################################################\n",
    "\n",
    "# filenames = [\"train_001.json\", \"train_005.json\", \"train_010.json\", \"train_025.json\", \"train_050.json\"]\n",
    "filenames = [\"merged-diffobj.json\"]\n",
    "# filenames = os.listdir(\"../annotations/splits\")\n",
    "dir_path = \"../annotations/real/smallv1\"\n",
    "save_path = \"../annotations/real/SOTA/mdetr\"\n",
    "\n",
    "for filename in filenames: \n",
    "    filepath = os.path.join(dir_path, filename)\n",
    "    data = json.load(open(filepath))\n",
    "    images = data[\"images\"]\n",
    "    new_images = []\n",
    "    tokens = defaultdict(str)\n",
    "    for image in images: \n",
    "        caption = image[\"caption\"]\n",
    "        image[\"dataset_name\"] = \"refcoco\"\n",
    "        image[\"tokens_negative\"] = [[0, len(caption)]]\n",
    "        tokens[image[\"id\"]] = image[\"tokens_negative\"]\n",
    "        new_images.append(image)\n",
    "\n",
    "    data[\"images\"] = new_images\n",
    "\n",
    "    for ann in data[\"annotations\"]:\n",
    "        ann[\"tokens_positive\"] = tokens[ann[\"image_id\"]]\n",
    "    \n",
    "    new_filename = filename.split(\".\")[0] + \"_mdetr.json\"\n",
    "    new_filepath = os.path.join(save_path, new_filename)\n",
    "    # data.pop(\"input_oracle_annotations\")\n",
    "    if \"segmentation_images\" in data.keys():\n",
    "        data.pop(\"segmentation_images\")\n",
    "    json.dump(data, open(new_filepath, \"w\"))\n",
    "\n",
    "    for ann in data[\"annotations\"]: \n",
    "        ann[\"category_id\"] = 1 \n",
    "    \n",
    "    for ann in data[\"input_oracle_annotations\"]:\n",
    "        ann[\"category_id\"] = 1 \n",
    "    \n",
    "\n",
    "    json.dump(data, open(os.path.join(save_path, filename.split(\".\")[0] + \"_gt.json\"), \"w\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5c76443",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../annotations/SOTA/mdetr/splits\\\\annotations_test_mdetr.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m test_filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mannotations_test_mdetr.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m test_filepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_path, test_filename)\n\u001b[1;32m----> 4\u001b[0m test_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39;49m(test_filepath))\n\u001b[0;32m      7\u001b[0m ablation \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mo+d+\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mo+d-\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mo-d+\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mo-d-\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m ablation: \n",
      "File \u001b[1;32mc:\\Users\\clshe\\Documents\\python-envs\\ai_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../annotations/SOTA/mdetr/splits\\\\annotations_test_mdetr.json'"
     ]
    }
   ],
   "source": [
    "test_filename = \"annotations_test_mdetr.json\"\n",
    "test_filepath = os.path.join(save_path, test_filename)\n",
    "\n",
    "test_data = json.load(open(test_filepath))\n",
    "\n",
    "\n",
    "ablation = [\"o+d+\", \"o+d-\", \"o-d+\", \"o-d-\"]\n",
    "\n",
    "for a in ablation: \n",
    "    new_images = []\n",
    "    new_annotations = []\n",
    "    tokens = defaultdict(str)\n",
    "    ablation_data = deepcopy(test_data)\n",
    "\n",
    "    for image in ablation_data[\"images\"]:\n",
    "\n",
    "        if a == \"o+d+\": \n",
    "            caption = image[\"caption\"]\n",
    "        elif a == \"o+d-\":\n",
    "            caption = \" \".join(image[\"caption\"].split(\" \")[1:])\n",
    "        elif a == \"o-d+\":\n",
    "            caption = image[\"caption\"].split(\" \")[0]\n",
    "        elif a == \"o-d-\":\n",
    "            caption = \"  \"\n",
    "\n",
    "        image[\"caption\"] = caption \n",
    "        image[\"tokens_negative\"] = [[0, len(caption)]]\n",
    "        tokens[image[\"id\"]] = image[\"tokens_negative\"]\n",
    "        new_images.append(image)\n",
    "    \n",
    "    for annotation in ablation_data[\"annotations\"]:\n",
    "        annotation[\"tokens_positive\"] = tokens[annotations[\"image_id\"]]\n",
    "        new_annotations.append(annotation)\n",
    "\n",
    "    ablation_data[\"images\"] = new_images\n",
    "    ablation_data[\"annotations\"] = new_annotations\n",
    "\n",
    "    ablation_filename = test_filename.split(\".\")[0] + \"_\" + a + \".json\"\n",
    "    ablation_dir_path = os.path.join(dir_path, \"ablation/mdetr\")\n",
    "    ablation_filepath = os.path.join(ablation_dir_path, ablation_filename)\n",
    "\n",
    "    json.dump(ablation_data, open(ablation_filepath, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85c526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b9cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f762b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "98f310addaf7dac00cd5965e6c1c6cb4dc304674e0e6e4d0010a991e9aec678e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
