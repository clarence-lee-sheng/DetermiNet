{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9436be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import inflection as inf\n",
    "from collections import defaultdict\n",
    "import random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d8a048b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "############################# CHANGE FILENAMES HERE ###################################\n",
    "#######################################################################################\n",
    "filenames = os.listdir(\"../annotations/splits\")\n",
    "annotation_dir = \"../annotations/splits\"\n",
    "determiners = [\"a\", \"an\", \"all\", \"any\", \"every\", \"my\", \"your\", \"this\", \"that\", \"these\", \"those\", \"some\", \"many\", \"few\", \"both\", \"neither\", \"little\", \"much\", \"either\", \"our\", \"no\", \"several\", \"half\", \"each\", \"the\"]\n",
    "# filenames = [\"annotations_val.json\", \"annotations_train.json\", \"annotations_test.json\"]\n",
    "# filenames = [\"annotations_val.json\"]\n",
    "# filenames = [\"train_001.json\", \"train_005.json\", \"train_010.json\", \"train_025.json\", \"train_050.json\"]\n",
    "\n",
    "save_dir = \"../annotations/tfrecords/neurosym\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3825c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = json.load(open(\"../annotations/annotations_val.json\", 'r'))\n",
    "categories = temp[\"categories\"]\n",
    "n_categories = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c76d7f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[tf.io.encode_png(value).numpy()])\n",
    "    )\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def int64_feature_list(value):\n",
    "    \"\"\"Returns a list of int_list from a int.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def float_feature_list(value):\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def object_features_list(objects): \n",
    "    feature_list = []\n",
    "    for obj in objects:\n",
    "        feature_list.append(int64_feature(obj[\"id\"]))\n",
    "    return tf.train.FeatureList(feature=feature_list)\n",
    "    \n",
    "\n",
    "def create_example(image_id, sample):\n",
    "    caption = sample[\"image\"][\"caption\"]\n",
    "    file_name = sample[\"image\"][\"file_name\"]\n",
    "    det = caption.split()[0]\n",
    "    noun = \" \".join(caption.split()[1:])\n",
    "    determiners.index(det)\n",
    "    noun_id = 0 \n",
    "    \n",
    "    noun = inf.singularize(noun)\n",
    "    for cat in categories: \n",
    "        if cat[\"name\"] == noun: \n",
    "            noun_id = cat[\"id\"]\n",
    "\n",
    "    det_one_hot = [0 for i in range(len(determiners))]\n",
    "    det_one_hot[determiners.index(det)] = 1\n",
    "    noun_one_hot = [0 for i in range(len(categories))]\n",
    "    noun_one_hot[noun_id] = 1\n",
    "    caption_one_hot = det_one_hot + noun_one_hot\n",
    "    \n",
    "    max_bboxes = 20 \n",
    "    \n",
    "    input_one_hot = []\n",
    "    output_one_hot =[]\n",
    "\n",
    "    inputs = sample[\"inputs\"]\n",
    "    outputs = sample[\"outputs\"]\n",
    "    \n",
    "    for ann in outputs: \n",
    "        one_hot = [0 for i in range(n_categories)]\n",
    "        one_hot[ann[\"category_id\"]] = 1\n",
    "        output_one_hot.append(ann[\"bbox\"] + [1] + one_hot)\n",
    "\n",
    "    for j in range(len(output_one_hot), max_bboxes): \n",
    "        one_hot = [0 for i in range(n_categories)]\n",
    "        output_one_hot.append([0,0,0,0] + [0] + one_hot)\n",
    "            \n",
    "    for ann in inputs: \n",
    "        one_hot = [0 for i in range(n_categories)]\n",
    "        one_hot[ann[\"category_id\"]] = 1\n",
    "        if \"liqLevel\" not in ann.keys():\n",
    "            ann[\"liqLevel\"] = -1\n",
    "        input_one_hot.append(ann[\"bbox\"] + [1] + one_hot + [ann[\"liqLevel\"]])\n",
    "        \n",
    "    for j in range(len(input_one_hot), max_bboxes): \n",
    "        one_hot = [0 for i in range(n_categories)]\n",
    "        input_one_hot.append([0,0,0,0] + [0] + one_hot)\n",
    "\n",
    "    #randonly shuffle a list of indices from 1 to 10\n",
    "    indices = list(range(len(input_one_hot)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    #shuffle input_one_hot according to indices\n",
    "    input_one_hot = [input_one_hot[i] for i in indices]\n",
    "    output_one_hot = [output_one_hot[i] for i in indices]\n",
    "        \n",
    "    context = {\n",
    "        # \"image\": image_feature(image),\n",
    "        \"file_name\": bytes_feature(file_name),\n",
    "        \"image_id\": int64_feature(image_id),\n",
    "        \"caption\": bytes_feature(caption),\n",
    "        \"caption_one_hot\": int64_feature_list(caption_one_hot),\n",
    "        \"areas\": int64_feature_list([ann['area'] for ann in inputs]), \n",
    "        \"category_ids\": int64_feature_list([ann['category_id'] for ann in inputs]), \n",
    "        \"output_category_ids\": int64_feature_list([ann['category_id'] for ann in outputs]),        \n",
    "        \"output_areas\": int64_feature_list([ann['area'] for ann in outputs]),\n",
    "    }\n",
    "\n",
    "    feature_list = {\n",
    "        \"input_bboxes\": tf.train.FeatureList(feature=[tf.train.Feature(int64_list=tf.train.Int64List(value=ann['bbox'])) for ann in inputs]),\n",
    "        \"output_bboxes\": tf.train.FeatureList(feature=[tf.train.Feature(int64_list=tf.train.Int64List(value=ann['bbox'])) for ann in outputs]), \n",
    "        \"input_one_hot\": tf.train.FeatureList(feature=[tf.train.Feature(int64_list=tf.train.Int64List(value=[int(v) for v in val])) for val in input_one_hot]),\n",
    "        \"output_one_hot\": tf.train.FeatureList(feature=[tf.train.Feature(int64_list=tf.train.Int64List(value=[int(v) for v in val])) for val in output_one_hot]),\n",
    "    }\n",
    "     \n",
    "    return tf.train.SequenceExample(context=tf.train.Features(feature=context), feature_lists=tf.train.FeatureLists(feature_list=feature_list))\n",
    "\n",
    "def parse_tfrecord_fn(example, labeled=True):\n",
    "    feature_description = {\n",
    "        \"file_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        #         \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"caption\": tf.io.VarLenFeature(tf.string),\n",
    "        \"caption_one_hot\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"areas\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"category_ids\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"output_category_ids\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"output_areas\": tf.io.VarLenFeature(tf.int64)\n",
    "    }\n",
    "\n",
    "    sequence_features = {\n",
    "        \"input_bboxes\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"output_bboxes\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"input_one_hot\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"output_one_hot\": tf.io.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    context, sequence = tf.io.parse_single_sequence_example(example, context_features=feature_description,\n",
    "                                                            sequence_features=sequence_features)\n",
    "\n",
    "    example = {**context, **sequence}\n",
    "    for key in example.keys():\n",
    "        if type(example[key]) == tf.sparse.SparseTensor:\n",
    "            if (example[key].dtype == \"string\"):\n",
    "                example[key] = tf.sparse.to_dense(example[key], default_value='b')\n",
    "            else:\n",
    "                example[key] = tf.sparse.to_dense(example[key])\n",
    "\n",
    "    prefix = \"../DetermiNetProject/Assets/StreamingAssets/dataset/\"\n",
    "    # raw = tf.io.read_file(prefix + example[\"file_name\"])\n",
    "    # example[\"image\"] = tf.io.decode_png(raw, channels=3)\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0218532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../annotations/tfrecords/neurosym\\0point1\n",
      "../annotations/tfrecords/neurosym\\0point25\n",
      "../annotations/tfrecords/neurosym\\1\n",
      "../annotations/tfrecords/neurosym\\10\n",
      "../annotations/tfrecords/neurosym\\25\n",
      "../annotations/tfrecords/neurosym\\2point5\n",
      "../annotations/tfrecords/neurosym\\5\n",
      "../annotations/tfrecords/neurosym\\50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filename in filenames:\n",
    "    annotation_filepath = os.path.join(annotation_dir, filename)\n",
    "    dataset = json.load(open(annotation_filepath, 'r'))\n",
    "    images = dataset[\"images\"]\n",
    "    input_annotations = dataset[\"input_oracle_annotations\"]\n",
    "    output_annotations = dataset[\"annotations\"]\n",
    "    n_samples = 4096\n",
    "    n_tfrecords = len(images) // n_samples\n",
    "    if len(images) % n_samples: \n",
    "        n_tfrecords += 1 \n",
    "    \n",
    "    split_dir = os.path.join(save_dir, filename.split(\".\")[0].split(\"_\")[1])\n",
    "    print(split_dir)\n",
    "    if not os.path.exists(split_dir): \n",
    "        os.makedirs(split_dir)\n",
    "\n",
    "    dataset_samples = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for ann in input_annotations: \n",
    "        dataset_samples[ann[\"image_id\"]][\"inputs\"].append(ann)\n",
    "        \n",
    "    for ann in output_annotations: \n",
    "        dataset_samples[ann[\"image_id\"]][\"outputs\"].append(ann)\n",
    "\n",
    "    for image in images: \n",
    "        dataset_samples[image[\"id\"]][\"image\"] = image\n",
    "\n",
    "    keys = list(dataset_samples.keys())\n",
    "    for tfrec_num in range(n_tfrecords): \n",
    "        sample_keys = keys[tfrec_num*n_samples : (tfrec_num + 1) * n_samples]\n",
    "        \n",
    "        with tf.io.TFRecordWriter(\n",
    "            split_dir + \"/file_%.2i-%i.tfrec\" % (tfrec_num, len(sample_keys))\n",
    "        ) as writer:\n",
    "            for key in sample_keys:\n",
    "                dataset_sample = dataset_samples[key] \n",
    "                input_objects = dataset_samples[key][\"input\"]\n",
    "                output_objects = dataset_samples[key][\"output\"]\n",
    "                example = create_example(key, dataset_sample)\n",
    "                writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "69073a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_inputs(example):\n",
    "    # image = example[\"image\"]\n",
    "    caption = example[\"caption\"]\n",
    "    input_bbox = example[\"input_bboxes\"]\n",
    "    input_label = example[\"category_ids\"]\n",
    "    output_labels = example[\"output_category_ids\"]\n",
    "    input_one_hot = tf.cast(example[\"input_one_hot\"], dtype=tf.float64)\n",
    "    output_bboxes = example[\"output_bboxes\"]\n",
    "    output_one_hot = tf.cast(example[\"output_one_hot\"], dtype=tf.float64)\n",
    "    caption_one_hot = example[\"caption_one_hot\"]\n",
    "    print(input_one_hot)\n",
    "\n",
    "    input_one_hot = tf.concat([input_one_hot[:, :4] / 256, input_one_hot[:, 4:]], axis=1)\n",
    "    output_one_hot = tf.concat([output_one_hot[:, :4] / 256, output_one_hot[:, 4:]], axis=1)\n",
    "    #     input_mask =\n",
    "    output_mask = tf.stack(output_one_hot[:, 4])\n",
    "    n_pad = 20 - tf.shape(output_labels)[0]\n",
    "    output_labels_padded = tf.pad(output_labels, [[0, n_pad]], \"CONSTANT\")\n",
    "    return (input_one_hot, caption_one_hot), (output_mask), output_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2c78511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['..\\\\annotations\\\\old\\\\file_00-104.tfrec']\n",
      "Tensor(\"Cast:0\", shape=(None, None), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "train_filenames = tf.io.gfile.glob(f\"../annotations/old/*.tfrec\")\n",
    "print(train_filenames)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(train_filenames, num_parallel_reads=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(map_to_inputs, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(4 * BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "example = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c07c4d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.], shape=(20,), dtype=float64)\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(20,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for i in example[1]: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e066273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.0625     0.14453125 0.12109375 0.125      1.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.28125    0.14453125 0.1640625  0.22265625 1.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.0859375  0.15625    0.28125    0.1796875  1.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.171875   0.11328125 0.10546875 0.109375   1.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]], shape=(20, 21), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(example[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "273eb85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0.])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d5576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "98f310addaf7dac00cd5965e6c1c6cb4dc304674e0e6e4d0010a991e9aec678e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
