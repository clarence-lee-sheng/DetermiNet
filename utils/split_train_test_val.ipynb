{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np \n",
    "import random \n",
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "############################# CHANGE FILENAMES HERE ###################################\n",
    "#######################################################################################\n",
    "\n",
    "annotations_dir = \"../annotations\"\n",
    "annotations_filename = \"annotations_full.json\"\n",
    "annotations_filepath = os.path.join(annotations_dir, annotations_filename)\n",
    "annotations = json.load(open(annotations_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['categories', 'images', 'segmentation_images', 'input_oracle_annotations', 'annotations', 'phrase_annotations'])\n"
     ]
    }
   ],
   "source": [
    "print(annotations.keys())\n",
    "categories = annotations[\"categories\"]\n",
    "images = annotations[\"images\"]\n",
    "det_annotations = annotations[\"annotations\"]\n",
    "oracle_annotations = annotations[\"input_oracle_annotations\"]\n",
    "segmentation_images = annotations[\"segmentation_images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_anns_map = defaultdict(list)\n",
    "oracle_anns_map = defaultdict(list)\n",
    "\n",
    "for ann in det_annotations:\n",
    "    det_anns_map[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "for ann in oracle_annotations:\n",
    "    oracle_anns_map[ann[\"image_id\"]].append(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = {}\n",
    "train_annotations[\"categories\"] = categories\n",
    "train_annotations[\"images\"] = []\n",
    "train_annotations[\"annotations\"] = []\n",
    "train_annotations[\"input_oracle_annotations\"] = []\n",
    "train_annotations[\"segmentation_images\"] = []\n",
    "\n",
    "val_annotations = {}\n",
    "val_annotations[\"categories\"] = categories\n",
    "val_annotations[\"images\"] = []\n",
    "val_annotations[\"annotations\"] = []\n",
    "val_annotations[\"input_oracle_annotations\"] = []\n",
    "val_annotations[\"segmentation_images\"] = []\n",
    "\n",
    "test_annotations = {}\n",
    "test_annotations[\"categories\"] = categories\n",
    "test_annotations[\"images\"] = []\n",
    "test_annotations[\"annotations\"] = []\n",
    "test_annotations[\"input_oracle_annotations\"] = []\n",
    "test_annotations[\"segmentation_images\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "19999\n",
      "29999\n",
      "39999\n",
      "49999\n",
      "59999\n",
      "69999\n",
      "79999\n",
      "89999\n",
      "99999\n",
      "109999\n",
      "119999\n",
      "129999\n",
      "139999\n",
      "149999\n",
      "159999\n",
      "169999\n",
      "179999\n",
      "189999\n",
      "199999\n",
      "209999\n",
      "219999\n",
      "229999\n",
      "239999\n",
      "249999\n"
     ]
    }
   ],
   "source": [
    "# randomly shuffle a list \n",
    "n_determiners = 25 \n",
    "n_samples_per_determiner = 10000\n",
    "\n",
    "train = 0.7 \n",
    "val = 0.1 \n",
    "test = 0.2\n",
    "\n",
    "for i in range(n_determiners): \n",
    "    # generate a list of random indexes from 1 to 10000\n",
    "    idxs = [j for j in range(i*n_samples_per_determiner, (i+1)*n_samples_per_determiner)]\n",
    "    np.random.shuffle(idxs)\n",
    "    n_train = int(train * n_samples_per_determiner)\n",
    "    n_val = int(val * n_samples_per_determiner)\n",
    "    n_test = n_samples_per_determiner - n_train - n_val\n",
    "\n",
    "    train_idxs = idxs[:n_train]\n",
    "    val_idxs = idxs[n_train:n_train+n_val]\n",
    "    test_idxs = idxs[n_train+n_val:]\n",
    "\n",
    "    for idx in train_idxs:\n",
    "        image = images[idx]\n",
    "        segmentation_image = segmentation_images[idx]\n",
    "        train_annotations[\"images\"].append(image)\n",
    "        train_annotations[\"annotations\"].extend(det_anns_map[image[\"id\"]])\n",
    "        train_annotations[\"input_oracle_annotations\"].extend(oracle_anns_map[image[\"id\"]])\n",
    "        train_annotations[\"segmentation_images\"].append(segmentation_image)\n",
    "\n",
    "    for idx in val_idxs:\n",
    "        image = images[idx]\n",
    "        segmentation_image = segmentation_images[idx]\n",
    "        val_annotations[\"images\"].append(image)\n",
    "        val_annotations[\"annotations\"].extend(det_anns_map[image[\"id\"]])\n",
    "        val_annotations[\"input_oracle_annotations\"].extend(oracle_anns_map[image[\"id\"]])\n",
    "        val_annotations[\"segmentation_images\"].append(segmentation_image)\n",
    "\n",
    "    for idx in test_idxs:\n",
    "        image = images[idx]\n",
    "        segmentation_image = segmentation_images[idx]\n",
    "        test_annotations[\"images\"].append(image)\n",
    "        test_annotations[\"annotations\"].extend(det_anns_map[image[\"id\"]])\n",
    "        test_annotations[\"input_oracle_annotations\"].extend(oracle_anns_map[image[\"id\"]])\n",
    "        test_annotations[\"segmentation_images\"].append(segmentation_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train annotations:  175000\n",
      "Length of val annotations:  25000\n",
      "Length of test annotations:  50000\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train annotations: \", len(train_annotations[\"images\"]))\n",
    "print(\"Length of val annotations: \", len(val_annotations[\"images\"]))\n",
    "print(\"Length of test annotations: \", len(test_annotations[\"images\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'a': 7000, 'an': 7000, 'all': 7000, 'any': 7000, 'every': 7000, 'my': 7000, 'your': 7000, 'this': 7000, 'that': 7000, 'these': 7000, 'those': 7000, 'some': 7000, 'many': 7000, 'few': 7000, 'both': 7000, 'neither': 7000, 'little': 7000, 'much': 7000, 'either': 7000, 'our': 7000, 'no': 7000, 'the': 7000, 'half': 7000, 'several': 7000, 'each': 7000})\n"
     ]
    }
   ],
   "source": [
    "det_counts = defaultdict(int)\n",
    "\n",
    "for images in train_annotations[\"images\"]:\n",
    "    caption = images[\"caption\"]\n",
    "    det = caption.split(\" \")[0]\n",
    "    det_counts[det] += 1\n",
    "\n",
    "print(det_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the annotations\n",
    "\n",
    "train_annotations_filename = \"annotations_train.json\"\n",
    "train_annotations_filepath = os.path.join(annotations_dir, train_annotations_filename)\n",
    "json.dump(train_annotations, open(train_annotations_filepath, \"w\"))\n",
    "\n",
    "val_annotations_filename = \"annotations_val.json\"\n",
    "val_annotations_filepath = os.path.join(annotations_dir, val_annotations_filename)\n",
    "json.dump(val_annotations, open(val_annotations_filepath, \"w\"))\n",
    "\n",
    "test_annotations_filename = \"annotations_test.json\"\n",
    "test_annotations_filepath = os.path.join(annotations_dir, test_annotations_filename)\n",
    "json.dump(test_annotations, open(test_annotations_filepath, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train into 1, 5, 10, 25, 50, 100% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_filename = \"annotations_train.json\"\n",
    "annotations_dir = \"../../annotations/old\"\n",
    "save_dir = os.path.join(annotations_dir, \"splits\")\n",
    "annotations_filepath = os.path.join(annotations_dir, annotations_filename)\n",
    "annotations = json.load(open(annotations_filepath))\n",
    "\n",
    "n_determiners = 25 \n",
    "categories = annotations[\"categories\"]\n",
    "images = annotations[\"images\"]\n",
    "det_annotations = annotations[\"annotations\"]\n",
    "oracle_annotations = annotations[\"input_oracle_annotations\"]\n",
    "segmentation_images = annotations[\"segmentation_images\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_anns_map = defaultdict(list)\n",
    "oracle_anns_map = defaultdict(list)\n",
    "\n",
    "for ann in det_annotations:\n",
    "    det_anns_map[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "for ann in oracle_annotations:\n",
    "    oracle_anns_map[ann[\"image_id\"]].append(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175000\n"
     ]
    }
   ],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_per_determiner = len(images)//n_determiners\n",
    "\n",
    "splits = [0.1, 0.25, 1, 2.5, 5, 10, 25, 50]\n",
    "\n",
    "for split in splits:\n",
    "    split_annotation = {\n",
    "        \"categories\": categories,\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"input_oracle_annotations\": [],\n",
    "        \"segmentation_images\": []\n",
    "    }\n",
    "\n",
    "    for i in range(n_determiners): \n",
    "        idxs = [j for j in range(i*n_samples_per_determiner, (i+1)*n_samples_per_determiner)]\n",
    "        np.random.shuffle(idxs)\n",
    "        \n",
    "        n_samples = int(split/100 * n_samples_per_determiner)\n",
    "        \n",
    "        idxs = idxs[:n_samples]\n",
    "\n",
    "        for idx in idxs:\n",
    "            image = images[idx]\n",
    "            segmentation_image = segmentation_images[idx]\n",
    "            split_annotation[\"images\"].append(image)\n",
    "            split_annotation[\"annotations\"].extend(det_anns_map[image[\"id\"]])\n",
    "            split_annotation[\"input_oracle_annotations\"].extend(oracle_anns_map[image[\"id\"]])\n",
    "            split_annotation[\"segmentation_images\"].append(segmentation_image)\n",
    "\n",
    "    split_annotation_filename = f\"train_{str(split).replace(\".\", \"point\")}.json\"\n",
    "    split_annotation_filepath = os.path.join(save_dir, split_annotation_filename)\n",
    "    json.dump(split_annotation, open(split_annotation_filepath, \"w\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750\n"
     ]
    }
   ],
   "source": [
    "annotations = json.load(open(os.path.join(save_dir, \"1_train.json\")))\n",
    "print(len(annotations[\"images\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98f310addaf7dac00cd5965e6c1c6cb4dc304674e0e6e4d0010a991e9aec678e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
